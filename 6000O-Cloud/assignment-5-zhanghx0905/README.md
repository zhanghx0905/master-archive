[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-24ddc0f5d75046c5622901739e7c5dd533143b0c8e959d652212380cedb1ea36.svg)](https://classroom.github.com/a/CPXxOeQl)
# CSIT6000O Assignment-5 (6 marks)

### Deadline: Apr 30, 23:59 (Sunday)

---

In this assignment, you will write a pipeline of machine learning application in Spark. This assignment repository consists of only one IPython notebook:

* `ml_pipeline.ipynb`

**Note:** Make sure you have completed [this](https://classroom.github.com/a/T7M6DUYp) self-paced Spark tutorial. We will be running the notebook on **the same platform** (Databricks) for the tutorial.

The following instructions assume that you have successfully imported the notebook to your workspace. If you don't know how, please refer to `README.md` file in the it repo of the self-paced Spark tutorial. To keep your environment consistent, set the Databricks runtime version as `Runtime: 11.3 LTS (Scala 2.12, Spark 3.3.0)`.

## Machine Learning Pipeline (**6 marks**)

Open the notebook file (`ml_pipeline.ipynb`) in your web browser and follow the instructions carefully. Once you've done coding, you'll submit **your Python code** to GitHub for autograding.

### Grading

You need to download the assignment code from your IPython Notebook environment. In the notebook web UI, In the notebook web UI, you can click on "File", then hovering your mouse over "Export", and then clicking on "Source File". This will export your IPython Notebook as a `ml_pipeline.py` file to your computer. You can `git add` this file, then commit and push it to GitHub to submit your code.
